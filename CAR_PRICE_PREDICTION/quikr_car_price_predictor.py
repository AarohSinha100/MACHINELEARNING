# -*- coding: utf-8 -*-
"""QUIKR_cAR_PRICE_PREDICTOR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pMkjhNPnXLaysBs6bBSra8J9w4oKLEfr

## Linear Regression Model
`Test Case` - To predict the price of car using the quikr car dataset
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import files
uploaded = files.upload() #Get the text data

car_df = pd.read_csv("car_dataset.txt")
car_df.to_csv("car_dataset.csv",
              index=None)
car_df.head()

car_df.shape

car_df.info()

"""## Data Cleaning

### Problem 1:
* Look at the year column, with the years specified, we also have a lot of unwanted noise, Year has many non year values
* Also year is in object form, not in int forms
"""

car_df["year"].unique()

"""## Problem 2
* On checking the uniue from price, we see some values such as "Ask for price" and all, we need to remove all of those
* Price is in object form, not in unique form
* Price contains comma in between
"""

car_df["Price"].unique()

"""## Problem 3
* kms driven is in object form asnd "kms" is given with the values
* also commas are given
* Has some nan values
"""

car_df["kms_driven"].unique()

car_df["kms_driven"].isnull().sum()

"""## Problem 4:
* Fuesl type contains some nan values
"""

car_df["fuel_type"].unique()

"""## Problem 5:
* Name column in going to be an important feature in our mode, the porblem here is that this name column is very inconsistent
* A good solution is to keep the first three words of the name
"""

car_df["name"].head()

"""# DATA CLEANING
First let's create a backup copy for this dataset
"""

backup = car_df.copy()

"""### CLEANING "YEAR"
#### 1. Removing the non year values
"""

car_df["year"].unique()

car_df["year"].isnull().sum()

#Checking if the string value is int then we keep it
car_df["year"].str.isnumeric()

# passing "car_df["year"].str.isnumeric()" this to the df
car_df = car_df[car_df["year"].str.isnumeric()]
car_df.head()

car_df["year"].unique()

"""#### 2. Converting the year to int"""

car_df["year"] = car_df["year"].astype(int)

car_df["year"].info()

"""## CLEARNING PRICE
#### 1.Removing the non price values
"""

car_df = car_df[car_df["Price"] != "Ask For Price"] #Those rows will be removed which contains ask for price

car_df["Price"].unique()

"""#### 2. Removing commas from pirce and converting them into int"""

price = car_df["Price"].iloc[0]
price

price = price.split(",")
price = "".join(price)
price

price = int(price)

type(price)

def convert_prices(price):
  val = price.split(",")
  val = "".join(val)
  val = int(val)
  return val

car_df["Price"] =  car_df["Price"].apply(lambda x: convert_prices(x))
car_df["Price"].info()

"""## KMS DRIVEN
#### 1. Has kms in the end
"""

car_df["kms_driven"].iloc[0]

car_df = car_df[car_df["kms_driven"]!="Petrol"]
car_df["kms_driven"].unique()

kms= car_df["kms_driven"].iloc[0]

def convert_kms(value):
  val = value.split(" ")
  val = val[0]
  return convert_prices(val)

car_df["kms_driven"] = car_df["kms_driven"].apply(lambda x:convert_kms(x))
car_df.info()

"""## Fuel Type"""

car_df["fuel_type"].unique()

car_df = car_df.dropna()
car_df.info()

"""## Name_"""

car_df["name"]
def convert_names(value):
  val = value.split(" ")[:3]
  return " ".join(val)

car_df["name"] = car_df["name"].apply(lambda x: convert_names(x))
car_df.head()

car_df = car_df.reset_index(drop=True)
car_df

car_df.describe()

"""* Note in the describe mothod , we see that 70% of cars have price below 5 lakhs but the max one is 85, this is an outlier
* Let's check the outliers above 60alkhs
* And remove that outlier
"""

car_df = car_df[car_df["Price"]<6e6].reset_index(drop=True)

car_df

car_df.to_csv("Cleaned_Car.csv")

"""# MODEL BUILDING"""

from sklearn.model_selection import train_test_split

X = car_df.drop("Price",axis=1)
y = car_df["Price"]

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)

from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import make_column_transformer
from sklearn.pipeline import make_pipeline

ohe = OneHotEncoder()
ohe.fit(X[["name","company","fuel_type"]]) #Fitting all the categorical values

#Column transformer - transforms columns, we pass the provided columns through this transformer and then the remainder columns get passedthrough
col_trans = make_column_transformer((OneHotEncoder(categories=ohe.categories_), ["name","company","fuel_type"]),
                                    remainder="passthrough")

lr = LinearRegression()

pipeline = make_pipeline(col_trans, lr) #First the data goes throught the column transformer, then it gets passed through the lr model

pipeline.fit(X_train, y_train) #The provided columns from above ["name","company","fuel_type"] will first get transformed in this pipelines encoder (as they are specified) and then the datas are passed
# So when we will pass input datas as the final product, the will go throught this pipeline, get transformed and come out.

y_pred = pipeline.predict(X_test) #We are sending raw data, it will get encoded on its own in the pipeline
y_pred

r2_score(y_test, y_pred)

"""## We can get the random state which give the best split for the accuracy"""

scores = []
for i in range(1000):
  X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=i)
  lr=LinearRegression()
  pipeline = make_pipeline(col_trans, lr)
  pipeline.fit(X_train, y_train)
  y_pred = pipeline.predict(X_test)
  scores.append(r2_score(y_test, y_pred))

np.argmax(scores)

scores[np.argmax(scores)]

"""We are getting max r2 scores of 84% at random state of 433. This is because our data is very very small and this gives variations in diffrent r2 scores for diffrent splits

### Training the best model
"""

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=433)
lr=LinearRegression()
pipeline = make_pipeline(col_trans, lr)
pipeline.fit(X_train, y_train)
y_pred = pipeline.predict(X_test)
r2_score(y_test, y_pred)

# Dumping the pipeling
import pickle
pickle.dump(pipeline, open("LinearRegressionModel.pkl","wb")) #pickle.dump is a function provided by the pickle module in Python that allows you to serialize (i.e., convert to a byte stream) and save Python objects to a file.

pipeline.predict(pd.DataFrame([['Maruti Suzuki Swift','Maruti',2019,100,'Petrol']],columns=['name','company','year','kms_driven','fuel_type']))

